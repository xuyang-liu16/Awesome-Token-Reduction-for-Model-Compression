### Image:

- **[1] Efficient Vision Transformer via Token Merger**, TIP 2023.
  
  *Feng, Zhanzhou and Zhang, Shiliang.*

  [[Paper](https://ieeexplore.ieee.org/abstract/document/10183862)] [Code] ![](https://img.shields.io/badge/TokenMerger-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[2] Token Merging: Your ViT But Faster**, ICLR 2023.
  
  *Bolya, Daniel and Fu, Cheng-Yang and Dai, Xiaoliang and Zhang, Peizhao and Feichtenhofer, Christoph and Hoffman, Judy.*

  [[Paper](https://arxiv.org/abs/2210.09461)] [Code] ![](https://img.shields.io/badge/ToMe-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[3] Efficient Transformer Adaptation with Soft Token Merging**, CVPRW 2024.
  
  *Yuan, Xin and Fei, Hongliang and Baek, Jinoo.*

  [[Paper](https://openaccess.thecvf.com/content/CVPR2024W/ELVM/papers/Yuan_Efficient_Transformer_Adaptation_with_Soft_Token_Merging_CVPRW_2024_paper.pdf)] [Code] ![](https://img.shields.io/badge/SoftToMe-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[4] Agglomerative Token Clustering**, ECCV 2024.
  
  *Haurum, Joakim Bruslund and Escalera, Sergio and Taylor, Graham W and Moeslund, Thomas B.*

  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-72998-0_12)] [Code] ![](https://img.shields.io/badge/ATC-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Clustering_Based-purple) ![](https://img.shields.io/badge/Token_Clustering-orange)

- **[5] Token Pruning using a Lightweight Background Aware Vision Transformer**, arXiv 2024.
  
  *Sah, Sudhakar and Kumar, Ravish and Rohmetra, Honnesh and Saboori, Ehsan.*

  [[Paper](https://arxiv.org/abs/2410.09324)] [Code] ![](https://img.shields.io/badge/BAViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[6] DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification**, NeurIPS 2021.
  
  *Rao, Yongming and Zhao, Wenliang and Liu, Benlin and Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui.*

  [[Paper](https://proceedings.neurips.cc/paper/2021/hash/747d3443e319a22747fbb873e8b2f9f2-Abstract.html)] [Code] ![](https://img.shields.io/badge/DynamicViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Sparsification-orange)

- **[7] GTP-ViT: Efficient Vision Transformers via Graph-Based Token Propagation**, WACV 2024.
  
  *Xu, Xuwei and Wang, Sen and Chen, Yudong and Zheng, Yanping and Wei, Zhewei and Liu, Jiajun.*

  [[Paper](https://openaccess.thecvf.com/content/WACV2024/html/Xu_GTP-ViT_Efficient_Vision_Transformers_via_Graph-Based_Token_Propagation_WACV_2024_paper.html)] [Code] ![](https://img.shields.io/badge/GTP_ViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Propagation-orange)

- **[8] PRANCE: Joint Token-Optimization and Structural Channel-Pruning for Adaptive ViT Inference**, arXiv 2024.
  
  *Li, Ye and Tang, Chen and Meng, Yuan and Fan, Jiajun and Chai, Zenghao and Ma, Xinzhu and Wang, Zhi and Zhu, Wenwu.*

  [[Paper](https://arxiv.org/abs/2407.05010)] [Code] ![](https://img.shields.io/badge/PRANCE-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Optimization-orange)

- **[9] TPC-ViT: Token Propagation Controller for Efficient Vision Transformer**, arXiv 2024.
  
  *Zhu, Wentao.*

  [[Paper](https://arxiv.org/abs/2401.01470)] [Code] ![](https://img.shields.io/badge/TPC_ViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Propagation-orange)

- **[10] Efficient Visual Transformer by Learnable Token Merging**, arXiv 2024.
  
  *Wang, Yancheng and Yang, Yingzhen.*

  [[Paper](https://arxiv.org/abs/2407.15219)] [Code] ![](https://img.shields.io/badge/LToMe-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[11] Unified Visual Transformer Compression**, arXiv 2022.
  
  *Yu, Shixing and Chen, Tianlong and Shen, Jiayi and Yuan, Huan and Tan, Jianchao and Yang, Sen and Liu, Ji and Wang, Zhangyang.*

  [[Paper](https://arxiv.org/abs/2203.08243)] [Code] ![](https://img.shields.io/badge/UVC-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Compression-orange)

- **[12] TempMe: Video Temporal Token Merging for Efficient Text-Video Retrieval**, arXiv 2024.
  
  *Shen, Leqi and Hao, Tianxiang and Zhao, Sicheng and Zhang, Yifeng and Liu, Pengzhang and Bao, Yongjun and Ding, Guiguang.*

  [[Paper](https://arxiv.org/abs/2409.01156)] [Code] ![](https://img.shields.io/badge/TempMe-blue) ![](https://img.shields.io/badge/Video_Retrieval-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[13] HeatViT: Hardware-Efficient Adaptive Token Pruning for Vision Transformers**, HPCA 2023.
  
  *Dong, Peiyan and Sun, Mengshu and Lu, Alec and Xie, Yanyue and Liu, Kenneth and Kong, Zhenglun and Meng, Xin and Li, Zhengang and Lin, Xue and Fang, Zhenman and others.*

  [[Paper](https://ieeexplore.ieee.org/abstract/document/10071047)] [Code] ![](https://img.shields.io/badge/HeatViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[14] Learning to Merge Tokens via Decoupled Embedding for Efficient Vision Transformers**, arXiv 2024.
  
  *Lee, Dong Hoon and Hong, Seunghoon.*

  [[Paper](https://arxiv.org/abs/2412.10569)] [Code] ![](https://img.shields.io/badge/DEToMe-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[15] AdapTiV: Sign-Similarity Based Image-Adaptive Token Merging for Vision Transformer Acceleration**, MICRO 2024.
  
  *Yoo, Seungjae and Kim, Hangyeol and Kim, Joo-Young.*

  [[Paper](https://ieeexplore.ieee.org/abstract/document/10764572)] [Code] ![](https://img.shields.io/badge/AdapTiV-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Sign_Similarity-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[16] Energy Minimizing-based Token Merging for Accelerating Transformers**, Workshop on practical ML 2024.
  
  *Tran, Hoai-Chau and Nguyen, Duy Minh Ho and Nguyen, Manh-Duy and Le, Ngan Hoang and Nguyen, Binh T.*

  [[Paper](https://openreview.net/forum?id=R7dCHc2Rp0)] [Code] ![](https://img.shields.io/badge/EMToMe-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Energy_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[17] Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention Graph in Pre-Trained Transformers**, CVPR 2024.
  
  *Wang, Hongjie and Dedhia, Bhishma and Jha, Niraj K.*

  [[Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Zero-TPrune_Zero-Shot_Token_Pruning_through_Leveraging_of_the_Attention_Graph_CVPR_2024_paper.html)] [Code] ![](https://img.shields.io/badge/Zero_TPrune-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Graph-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[18] Shunted Self-Attention via Multi-Scale Token Aggregation**, CVPR 2022.
  
  *Ren, Sucheng and Zhou, Daquan and He, Shengfeng and Feng, Jiashi and Wang, Xinchao.*

  [[Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Shunted_Self-Attention_via_Multi-Scale_Token_Aggregation_CVPR_2022_paper.html)] [Code] ![](https://img.shields.io/badge/SSA-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Aggregation-orange)

- **[19] Dynamic Token Pruning in Plain Vision Transformers for Semantic Segmentation**, ICCV 2023.
  
  *Tang, Quan and Zhang, Bowen and Liu, Jiajun and Liu, Fagui and Liu, Yifan.*

  [[Paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.html)] [Code] ![](https://img.shields.io/badge/DTP-blue) ![](https://img.shields.io/badge/Semantic_Segmentation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[20] Token Turing Machines are Efficient Vision Models**, arXiv 2024.
  
  *Jajal, Purvish and Eliopoulos, Nick John and Chou, Benjamin Shiue-Hal and Thiravathukal, George K and Davis, James C and Lu, Yung-Hsiang.*

  [[Paper](https://arxiv.org/abs/2409.07613)] [Code] ![](https://img.shields.io/badge/TTM-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Processing-orange)

- **[21] Making Vision Transformers Efficient From a Token Sparsification View**, CVPR 2023.
  
  *Chang, Shuning and Wang, Pichao and Lin, Ming and Wang, Fan and Zhang, David Junhao and Jin, Rong and Shou, Mike Zheng.*

  [[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Chang_Making_Vision_Transformers_Efficient_From_a_Token_Sparsification_View_CVPR_2023_paper.html)] [Code] ![](https://img.shields.io/badge/TSViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Sparsification-orange)

- **[22] PSViT: Better Vision Transformer via Token Pooling and Attention Sharing**, arXiv 2021.
  
  *Chen, Boyu and Li, Peixia and Li, Baopu and Li, Chuming and Bai, Lei and Lin, Chen and Sun, Ming and Yan, Junjie and Ouyang, Wanli.*

  [[Paper](https://arxiv.org/abs/2108.03428)] [Code] ![](https://img.shields.io/badge/PSViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pooling-orange)

- **[23] Content-Aware Token Sharing for Efficient Semantic Segmentation With Vision Transformers**, CVPR 2023.
  
  *Lu, Chenyang and de Geus, Daan and Dubbelman, Gijs.*

  [[Paper](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Content-Aware_Token_Sharing_for_Efficient_Semantic_Segmentation_With_Vision_Transformers_CVPR_2023_paper.html)] [Code] ![](https://img.shields.io/badge/CATS-blue) ![](https://img.shields.io/badge/Semantic_Segmentation-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Sharing-orange)

- **[24] An Attention-Based Token Pruning Method for Vision Transformers**, IJCRS 2022.
  
  *Luo, Kaicheng and Li, Huaxiong and Zhou, Xianzhong and Huang, Bing.*

  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-21244-4_21)] [Code] ![](https://img.shields.io/badge/ATP-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[25] LookupViT: Compressing Visual Information to a Limited Number of Tokens**, ECCV 2025.
  
  *Koner, Rajat and Jain, Gagan and Jain, Prateek and Tresp, Volker and Paul, Sujoy.*

  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-73016-0_19)] [Code] ![](https://img.shields.io/badge/LookupViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Compression-orange)

- **[26] Exploring Token Pruning in Vision State Space Models**, arXiv 2024.
  
  *Zhan, Zheng and Kong, Zhenglun and Gong, Yifan and Wu, Yushu and Meng, Zichong and Zheng, Hangyu and Shen, Xuan and Ioannidis, Stratis and Niu, Wei and Zhao, Pu and others.*

  [[Paper](https://arxiv.org/abs/2409.18962)] [Code] ![](https://img.shields.io/badge/SSM_Pruning-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/State_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[27] M2M-TAG: Training-Free Many-to-Many Token Aggregation for Vision Transformer Acceleration**, NeurIPS Workshop 2024.
  
  *Zeng, Fanhu and Yu, Deli.*

  [[Paper](https://openreview.net/forum?id=LO3Mw8Jrk0)] [Code] ![](https://img.shields.io/badge/M2M_TAG-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Similarity_Based-purple) ![](https://img.shields.io/badge/Token_Aggregation-orange)

- **[28] Accelerating Transformer-Based Scene Text Detection and Recognition via Token Pruning**, ICDAR 2023.
  
  *Garcia-Bordils, Sergi and Karatzas, Dimosthenis and Rusiñol, Marçal.*

  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-41731-3_7)] [Code] ![](https://img.shields.io/badge/Text_TP-blue) ![](https://img.shields.io/badge/Text_Detection-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[29] AdaViT: Adaptive Tokens for Efficient Vision Transformer**, arXiv 2021.
  
  *Yin, Hongxu and Vahdat, Arash and Alvarez, Jose and Mallya, Arun and Kautz, Jan and Molchanov, Pavlo.*

  [[Paper](https://arxiv.org/abs/2112.07658)] [Code] ![](https://img.shields.io/badge/AdaViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Adaptation-orange)

- **[30] DOTA: Detect and Omit Weak Attentions for Scalable Transformer Acceleration**, ASPLOS 2022.
  
  *Qu, Zheng and Liu, Liu and Tu, Fengbin and Chen, Zhaodong and Ding, Yufei and Xie, Yuan.*

  [[Paper](https://dl.acm.org/doi/abs/10.1145/3503222.3507738)] [Code] ![](https://img.shields.io/badge/DOTA-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[31] Adaptive Sparse ViT: Towards Learnable Adaptive Token Pruning by Fully Exploiting Self-Attention**, arXiv 2022.
  
  *Liu, Xiangcheng and Wu, Tianyi and Guo, Guodong.*

  [[Paper](https://arxiv.org/abs/2209.13802)] [Code] ![](https://img.shields.io/badge/ASViT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[32] Training-Free Visual Token Compression via Delayed Spatial Merging**, NeurIPS 2024.

  [[Paper](https://openreview.net/forum?id=4JXo4wOUfQ)] [Code] ![](https://img.shields.io/badge/DSM-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Spatial_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[33] Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation**, ICCV 2023.

  [[Paper](https://arxiv.org/abs/2308.04549)] [Code] ![](https://img.shields.io/badge/PSTA-blue) ![](https://img.shields.io/badge/Video_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Semantic_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[34] Bridging The Gaps Between Token Pruning and Full Pre-training via Masked Fine-tuning**, arXiv 2023.

  [[Paper](https://arxiv.org/abs/2310.17177)] [Code] ![](https://img.shields.io/badge/MFT-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Based-brown) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[35] Attention Standard Deviation Based Token Sparsification**, IEEE Access 2024.

  [[Paper](https://ieeexplore.ieee.org/abstract/document/10548480)] [Code] ![](https://img.shields.io/badge/ASD-blue) ![](https://img.shields.io/badge/Image_Understanding-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Sparsification-orange)

- **[36] Efficient Video Transformers via Spatial-temporal Token Merging for Action Recognition**, ACM MM 2024.

  [[Paper](https://dl.acm.org/doi/abs/10.1145/3633781)] [Code] ![](https://img.shields.io/badge/STToMe-blue) ![](https://img.shields.io/badge/Action_Recognition-green) ![](https://img.shields.io/badge/Training_Free-brown) ![](https://img.shields.io/badge/Spatio_Temporal-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[37] Zero-TPrune: Zero-Shot Token Pruning through Attention Graph**, CVPR 2024.
  *Wang, Hongjie et al.*
  [[Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Wang_Zero-TPrune_Zero-Shot_Token_Pruning_through_Leveraging_of_the_Attention_Graph_CVPR_2024_paper.html)] [Code] ![](https://img.shields.io/badge/Zero_TPrune-blue) ![](https://img.shields.io/badge/Vision_Understanding-green) ![](https://img.shields.io/badge/Training_Free-red) ![](https://img.shields.io/badge/Attention_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[38] SPViT: Latency-Aware Soft Token Pruning**, ECCV 2022.
  *Kong, Zhenglun et al.*
  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-20083-0_37)] [Code] ![](https://img.shields.io/badge/SPViT-blue) ![](https://img.shields.io/badge/Vision_Understanding-green) ![](https://img.shields.io/badge/Training_Based-red) ![](https://img.shields.io/badge/Token_Pruning-orange)

- **[39] PaPr: Training-Free One-Step Patch Pruning**, ECCV 2025.
  *Mahmud, Tanvir et al.*
  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-73337-6_7)] [Code] ![](https://img.shields.io/badge/PaPr-blue) ![](https://img.shields.io/badge/Vision_Understanding-green) ![](https://img.shields.io/badge/Training_Free-red) ![](https://img.shields.io/badge/Patch_Based-purple) ![](https://img.shields.io/badge/Token_Pruning-orange)


- **[40] Learning to Merge Tokens via Decoupled Embedding**, arXiv 2024.
  *Lee, Dong Hoon and Hong, Seunghoon.*
  [[Paper](https://arxiv.org/abs/2412.10569)] [Code] ![](https://img.shields.io/badge/DecoupledToMe-blue) ![](https://img.shields.io/badge/Vision_Understanding-green) ![](https://img.shields.io/badge/Training_Based-red) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[41] Segformer++: Token-Merging for Semantic Segmentation**, arXiv 2024.
  *Kienzle, Daniel et al.*
  [[Paper](https://arxiv.org/abs/2405.14467)] [Code] ![](https://img.shields.io/badge/Segformer++-blue) ![](https://img.shields.io/badge/Segmentation-green) ![](https://img.shields.io/badge/Training_Based-red) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[42] Vote&Mix: Plug-and-Play Token Reduction**, arXiv 2024.
  *Peng, Shuai et al.*
  [[Paper](https://arxiv.org/abs/2408.17062)] [Code] ![](https://img.shields.io/badge/Vote&Mix-blue) ![](https://img.shields.io/badge/Vision_Understanding-green) ![](https://img.shields.io/badge/Training_Free-red) ![](https://img.shields.io/badge/Voting_Based-purple) ![](https://img.shields.io/badge/Token_Merging-orange)

- **[43] ToSA: Token Selective Attention**, arXiv 2024.
  *Singh, Manish Kumar et al.*
  [[Paper](https://arxiv.org/abs/2406.08816)] [Code] ![](https://img.shields.io/badge/ToSA-blue) ![](https://img.shields.io/badge/Vision_Understanding-green) ![](https://img.shields.io/badge/Training_Based-red) ![](https://img.shields.io/badge/Token_Selection-orange)

- **[44] A-ViT: Adaptive Tokens**, CVPR 2022.
  *Yin, Hongxu et al.*
  [[Paper](https://openaccess.thecvf.com/content/CVPR2022/html/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.html)] [Code] ![](https://img.shields.io/badge/A_ViT-blue) ![](https://img.shields.io/badge/Vision_Understanding-green) ![](https://img.shields.io/badge/Training_Based-red) ![](https://img.shields.io/badge/Adaptive_Token-orange)

- **[45] TokenLearner: Adaptive Space-Time Tokenization**, NeurIPS 2021.
  *Ryoo, Michael et al.*
  [[Paper](https://proceedings.neurips.cc/paper/2021/hash/6a30e32e56fce5cf381895dfe6ca7b6f-Abstract.html)] [Code] ![](https://img.shields.io/badge/TokenLearner-blue) ![](https://img.shields.io/badge/Video_Understanding-green) ![](https://img.shields.io/badge/Training_Based-red) ![](https://img.shields.io/badge/Adaptive_Token-orange)
